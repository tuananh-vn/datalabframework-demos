{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engines:\n",
      "  spark:\n",
      "    config:\n",
      "      jars:\n",
      "      - /home/jovyan/demo/jars/ojdbc6-11.2.0.3.jar\n",
      "      jobname: default\n",
      "      master: spark://spark-master:7077\n",
      "      packages:\n",
      "      - mysql:mysql-connector-java:8.0.12\n",
      "    context: spark\n",
      "loggers:\n",
      "  stream:\n",
      "    enable: true\n",
      "    severity: info\n",
      "profile: ingest-prod\n",
      "providers:\n",
      "  ingest:\n",
      "    format: parquet\n",
      "    hostname: hdfs-nn\n",
      "    path: /data/ingest\n",
      "    service: hdfs\n",
      "    write:\n",
      "      coalesce: 2\n",
      "      options:\n",
      "        mode: append\n",
      "        partitionBy:\n",
      "        - date\n",
      "      repartition: 4\n",
      "  source:\n",
      "    database: MMSOFF\n",
      "    hostname: 172.16.60.18\n",
      "    password: qazwsxedcrfv\n",
      "    port: 1521\n",
      "    read:\n",
      "      cache: true\n",
      "      repartition: 4\n",
      "    service: oracle\n",
      "    sid: offline\n",
      "    username: sys as sysdba\n",
      "resources:\n",
      "  .resources.QR_Transaction_Refund:\n",
      "    path: QR_Transaction_Refund\n",
      "    provider: source\n",
      "variables:\n",
      "  a: 5\n",
      "  b: hello\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlf.project.profile('ingest-prod')\n",
    "dlf.utils.pretty_print(dlf.params.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR_Transaction_Refund\n",
      "jdbc:oracle:thin:sys as sysdba/qazwsxedcrfv@//172.16.60.18:1521/offline\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-0300888054fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/datalabframework/datalabframework/engines.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, resource, path, provider, **kargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'database'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0;31m#             print(rmd['path'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"oracle.jdbc.driver.OracleDriver\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jdbc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "md = dlf.params.metadata()\n",
    "for resource in md['resources']:\n",
    "    ds = md['resources'][resource]\n",
    "    if ds['provider']=='source':\n",
    "        print(ds['path'])\n",
    "        # read\n",
    "        \n",
    "        engine.read(resource).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "address\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "category\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "city\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "country\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "customer\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "film\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "film_actor\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "film_category\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "film_text\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "inventory\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "language\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "payment\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "rental\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "staff\n",
      "jdbc:mysql://mysql:3306/sakila\n",
      "store\n",
      "jdbc:mysql://mysql:3306/sakila\n"
     ]
    }
   ],
   "source": [
    "day = md = dlf.params.metadata()\n",
    "for resource in md['resources']:\n",
    "    ds = md['resources'][resource]\n",
    "    if ds['provider']=='source':\n",
    "        print(ds['path'])\n",
    "        # read\n",
    "        df_src = engine.read(resource)\n",
    "        \n",
    "        # define target path\n",
    "        target_path = '{}.{}'.format(ds['provider'],ds['path'])\n",
    "        \n",
    "        # write\n",
    "        engine.write(df_src, target_path, 'ingest', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre checks\n",
    "\n",
    "schema checks:\n",
    "\n",
    " - get table schema from source\n",
    " - compare with reference schema\n",
    " \n",
    "value checks:\n",
    " - null\n",
    " - invalid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest strategy\n",
    "\n",
    "#### **what to read?**\n",
    " \n",
    "FULL scan:  \n",
    "tables are lost or never ingested before\n",
    " \n",
    "  - cold start\n",
    "  - disaster recovery from source\n",
    "     \n",
    "INCREMENTAL scan:  \n",
    "We need a way to select/filter new data\n",
    "\n",
    "  - time based (default, i.e. last_update column)\n",
    "  - index based (if index is auto incrementing)\n",
    "  - hash compare indexes (expensive)\n",
    "  - full rescan and tag with ingest date\n",
    " \n",
    "#### **where to write?**\n",
    "\n",
    "  - define a naming convention for the target tables (default schema version: `latest`)  \n",
    "    `<source>/<db-name>/<table-name>/<schema-version-date>`\n",
    "    \n",
    "#### **exceptions**\n",
    ": what to do? (show error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://hdfs-nn:8020//data/ingest/extract/sakila.actor\n",
      "+--------+----------+------------+-------------------+\n",
      "|actor_id|first_name|   last_name|        last_update|\n",
      "+--------+----------+------------+-------------------+\n",
      "|       1|  PENELOPE|     GUINESS|2006-02-15 04:34:33|\n",
      "|       2|      NICK|    WAHLBERG|2006-02-15 04:34:33|\n",
      "|       3|        ED|       CHASE|2006-02-15 04:34:33|\n",
      "|       4|  JENNIFER|       DAVIS|2006-02-15 04:34:33|\n",
      "|       5|    JOHNNY|LOLLOBRIGIDA|2006-02-15 04:34:33|\n",
      "|       6|     BETTE|   NICHOLSON|2006-02-15 04:34:33|\n",
      "|       7|     GRACE|      MOSTEL|2006-02-15 04:34:33|\n",
      "|       8|   MATTHEW|   JOHANSSON|2006-02-15 04:34:33|\n",
      "|       9|       JOE|       SWANK|2006-02-15 04:34:33|\n",
      "|      10| CHRISTIAN|       GABLE|2006-02-15 04:34:33|\n",
      "|      11|      ZERO|        CAGE|2006-02-15 04:34:33|\n",
      "|      12|      KARL|       BERRY|2006-02-15 04:34:33|\n",
      "|      13|       UMA|        WOOD|2006-02-15 04:34:33|\n",
      "|      14|    VIVIEN|      BERGEN|2006-02-15 04:34:33|\n",
      "|      15|      CUBA|     OLIVIER|2006-02-15 04:34:33|\n",
      "|      16|      FRED|     COSTNER|2006-02-15 04:34:33|\n",
      "|      17|     HELEN|      VOIGHT|2006-02-15 04:34:33|\n",
      "|      18|       DAN|        TORN|2006-02-15 04:34:33|\n",
      "|      19|       BOB|     FAWCETT|2006-02-15 04:34:33|\n",
      "|      20|   LUCILLE|       TRACY|2006-02-15 04:34:33|\n",
      "+--------+----------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read back from hdfs in parquet format\n",
    "df_trg = engine.read('target', 'ingest')\n",
    "df_trg.where(col(colname) => 'datetime')\n",
    "df_trg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_src.subtract(df_trg).count()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.read(path='abcd', provider='dsds')\n",
    "write(df, path='abcd', provider='ingest')\n",
    "\n",
    "engine.read('resource_alias')\n",
    "engine.write(df, 'resource_alias')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}